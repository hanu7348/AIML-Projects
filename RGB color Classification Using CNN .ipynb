{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e59ef62-7bac-4e40-b1d0-1fb6bf608d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 images belonging to 3 classes.\n",
      "Found 6 images belonging to 3 classes.\n",
      "['blue', 'green', 'red']\n"
     ]
    }
   ],
   "source": [
    "# Import TensorFlow library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import Keras from TensorFlow\n",
    "from tensorflow import keras\n",
    "\n",
    "# Import layers module from Keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Import Dense layer from Keras layers\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Import PyDataset utility from Keras (Note: this import seems unused in the code)\n",
    "from keras.utils import PyDataset\n",
    "\n",
    "# Import ImageDataGenerator for image preprocessing and augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define image size (224x224 pixels)\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Define batch size for training\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create an ImageDataGenerator with rescaling and validation split\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Create a generator for training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\aryah\\Downloads\\RGB\\Train',  # Directory path for training images\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),  # Resize images to IMG_SIZE\n",
    "    batch_size=BATCH_SIZE,  # Use defined batch size\n",
    "    class_mode='categorical',  # Use categorical labels\n",
    "    subset='training'  # Specify this is the training subset\n",
    ")\n",
    "\n",
    "# Create a generator for validation data\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    r'C:\\Users\\aryah\\Downloads\\RGB\\Train',  # Directory path for validation images (same as training in this case)\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),  # Resize images to IMG_SIZE\n",
    "    batch_size=BATCH_SIZE,  # Use defined batch size\n",
    "    class_mode='categorical',  # Use categorical labels\n",
    "    subset='validation'  # Specify this is the validation subset\n",
    ")\n",
    "\n",
    "# Get the list of class names from the training generator\n",
    "classes = list(train_generator.class_indices)\n",
    "\n",
    "# Print the list of classes\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc80255-603d-4b58-8deb-8997959f3252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryah\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define a Sequential model\n",
    "model = keras.Sequential([\n",
    "    # First Convolutional layer\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,3)),\n",
    "    # Max Pooling layer after first Conv2D\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Second Convolutional layer\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    # Max Pooling layer after second Conv2D\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Third Convolutional layer\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    # Max Pooling layer after third Conv2D\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    # Flatten layer to convert 2D feature maps to 1D feature vector\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # First Dense (fully connected) layer\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    \n",
    "    # Output Dense layer with 3 units (assuming 3 classes) and softmax activation\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47fdfc4e-2a46-4377-bb28-476b4062b168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryah\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2s/step - accuracy: 0.3889 - loss: 3.6806 - val_accuracy: 0.3333 - val_loss: 4.6198\n",
      "Epoch 2/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.5926 - loss: 2.5463 - val_accuracy: 1.0000 - val_loss: 0.2701\n",
      "Epoch 3/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - accuracy: 0.8264 - loss: 0.3875 - val_accuracy: 1.0000 - val_loss: 0.0182\n",
      "Epoch 4/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 307ms/step - accuracy: 0.8264 - loss: 0.3866 - val_accuracy: 1.0000 - val_loss: 0.0984\n",
      "Epoch 5/5\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 360ms/step - accuracy: 0.9132 - loss: 0.1359 - val_accuracy: 1.0000 - val_loss: 0.0025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x28f47aefbd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',  # Use Adam optimizer\n",
    "    loss='categorical_crossentropy',  # Use categorical crossentropy loss for multi-class classification\n",
    "    metrics=['accuracy']  # Track accuracy metric during training\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,  # Use the training data generator\n",
    "    validation_data=val_generator,  # Use the validation data generator\n",
    "    epochs=5  # Train for 5 epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d45cd00-39d6-4fd8-bc1a-40bfbeaf5046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to a file named \"Model.h5\"\n",
    "model.save(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6568c61b-01e2-4c07-a808-9017cbe5f480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n"
     ]
    }
   ],
   "source": [
    "# Import the load_model function from Keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Import the image module from Keras preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Import numpy for array operations\n",
    "import numpy as np\n",
    "\n",
    "# Load the previously saved model from the file 'Model.h5'\n",
    "model = load_model('Model.h5')\n",
    "\n",
    "# Print a message indicating that the model has been loaded successfully\n",
    "print(\"Model Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45621cb2-f769-4235-9797-c7b133d29bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the path to the test image\n",
    "test_image_path = r\"C:\\Users\\aryah\\Downloads\\RGB\\Train\\green\\green13.jpg\"\n",
    "\n",
    "# Load the image and resize it to 224x224 pixels\n",
    "img = image.load_img(test_image_path, target_size=(224,224))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# Expand the dimensions of the array to create a batch of size 1\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd8033bc-9520-4525-836b-1bf73a8554ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441ms/step\n",
      "[[5.009647e-05 9.998969e-01 5.295366e-05]]\n",
      "1\n",
      "green\n"
     ]
    }
   ],
   "source": [
    "# Normalize the pixel values to the range [0, 1]\n",
    "img_array /= 255.\n",
    "\n",
    "# Use the model to make a prediction on the preprocessed image\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# Print the raw prediction array\n",
    "print(prediction)\n",
    "\n",
    "# Find the index of the highest probability in the prediction\n",
    "val = np.argmax(prediction)\n",
    "\n",
    "# Print the index of the predicted class\n",
    "print(val)\n",
    "\n",
    "# Print the name of the predicted class\n",
    "print(classes[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98919a3d-19dd-48ed-8e8c-2210bc80c3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
